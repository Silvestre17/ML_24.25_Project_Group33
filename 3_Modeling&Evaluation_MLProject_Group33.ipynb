{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1834cc3d7b582eb2",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap;\">\n",
    "    <div style=\"flex: 1; max-width: 400px; display: flex; justify-content: center;\">\n",
    "        <img src=\"https://i.ibb.co/JBPWVYR/Logo-Nova-IMS-Black.png\" style=\"max-width: 50%; height: auto; margin-top: 50px; margin-bottom: 50px;margin-left: 3rem;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 2; text-align: center; margin-top: 20px;\">\n",
    "        <div style=\"font-size: 28px; font-weight: bold; line-height: 1.2;\">\n",
    "            <span style=\"color: #08306B;\">ML Project |</span> <span style=\"color: #08529C;\">To Grant or Not to Grant</span>\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold; margin-top: 10px;\">\n",
    "            Fall Semester | 2024 - 2025\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold;\">\n",
    "            Master in Data Science and Advanced Analytics\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px;\">\n",
    "            <div>André Silvestre, 20240502</div>\n",
    "            <div>João Henriques, 20240499</div>\n",
    "            <div>Simone Genovese, 20241459</div>\n",
    "            <div>Steven Carlson, 20240554</div>\n",
    "            <div>Vinícius Pinto, 20211682</div>\n",
    "            <div>Zofia Wojcik, 20240654</div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px; font-weight: bold;\">\n",
    "            TBL Group 33\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6952549c",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,#08529C, #08529C); \n",
    "            padding: .7px; color: white; border-radius: 300px; text-align: center;\">\n",
    "</div>\n",
    "\n",
    "##### **Notebook Structure**\n",
    "\n",
    "<ol style=\"list-style-type: upper-roman;font-weight: bold;\">\n",
    "  <li><span style=\"font-weight: normal;\"><a href=\"#3\">Modeling & Evaluation</a></span></li>\n",
    "  <ol style=\"list-style-type:lower-alpha;\">\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#definition-of-the-problem\">Definition of the Problem</a></span></li>\n",
    "  </ol>\n",
    "  <br>\n",
    "\n",
    "  <ol style=\"list-style-type:alpha;\">\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#logistic-regression\">Logistic Regression</a></span></li>\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#naive-bayes\">Naive Bayes</a></span></li>\n",
    "    <ol style=\"list-style-type:lower-roman;\">\n",
    "      <li><span style=\"font-weight: normal;\"><a href=\"#naive-bayes-categorical\">Naive Bayes - Categorical</a></span></li>\n",
    "      <li><span style=\"font-weight: normal;\"><a href=\"#naive-bayes-gaussian\">Naive Bayes - Gaussian</a></span></li>\n",
    "    </ol>\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#knn\">K-Nearest Neighbors</a></span></li>\n",
    "    <ol style=\"list-style-type:lower-roman;\">\n",
    "      <li><span style=\"font-weight: normal;\"><a href=\"#knn-brute-force\">KNN - Brute Force</a></span></li>\n",
    "      <li><span style=\"font-weight: normal;\"><a href=\"#knn-kd-tree\">KNN - KD Tree</a></span></li>\n",
    "      <li><span style=\"font-weight: normal;\"><a href=\"#knn-ball-tree\">KNN - Ball Tree</a></span></li>\n",
    "      <li><span style=\"font-weight: normal;\"><a href=\"#knn-locally-weighted-learning\">KNN - Locally Weighted Learning (LWL)</a></span></li>\n",
    "    </ol>\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#neural-network\">Neural Network</a></span></li>\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#svm\">Support Vector Machine</a></span></li>\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#decision-tree\">Decision Tree</a></span></li>\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#random-forest\">Random Forest</a></span></li>\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#gradient-boosting\">Gradient Boosting</a></span></li>\n",
    "  </ol> <br>\n",
    "  <ol style=\"list-style-type:decimal;\">\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#3_1\">Model Selection</a></span></li>\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#3_2\">Model Evaluation</a></span></li>\n",
    "    <li><span style=\"font-weight: normal;\"><a href=\"#3_3\">Model Optimization</a></span></li>\n",
    "  </ol>\n",
    "  <li><span style=\"font-weight: normal;\"><a href=\"#📊-feature-importance\">Feature Importance</a></span></li>\n",
    "  <li><span style=\"font-weight: normal;\"><a href=\"#🔮-test-data-prediction\">Test Data Prediction</a></span></li>\n",
    "  <li><span style=\"font-weight: normal;\"><a href=\"#📋-csv-export---submission\">CSV Export - Submission [Kaggle]</a></span></li>\n",
    "</ol>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"background: linear-gradient(to right,#08529C, #08529C); \n",
    "            padding: .7px; color: white; border-radius: 300px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f603cf1cb0fd531",
   "metadata": {},
   "source": [
    "## **📚 Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b209518998b249d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:19:43.096268Z",
     "start_time": "2024-10-19T23:19:43.088149Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# For data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# For modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "\n",
    "# For evaluation\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve, auc, RocCurveDisplay, DetCurveDisplay\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, StratifiedKFold, learning_curve\n",
    "\n",
    "# Disable warnings [DataConversionWarning & ConvergenceWarning]\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning, ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "# Set the style of the visualization\n",
    "pd.set_option('display.max_columns', None) # display all columns\n",
    "\n",
    "# for better resolution plots\n",
    "%config InlineBackend.figure_format = 'retina' # optionally, you can change 'svg' to 'retina'\n",
    "\n",
    "# Setting seaborn style\n",
    "sns.set_theme(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b2091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to display multiple dataframes side by side\n",
    "# Source: https://python.plainenglish.io/displaying-multiple-dataframes-side-by-side-in-jupyter-lab-notebook-9a4649a4940\n",
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "def display_side_by_side(*args, super_title, titles=cycle([''])):\n",
    "    \"\"\"\n",
    "    :param args: Variable number of DataFrame objects to be displayed side by side.\n",
    "    :param super_title: The main title to be displayed at the top of the combined view.\n",
    "    :param titles: An iterable containing titles for each DataFrame to be displayed. Defaults to an infinite cycle of empty strings.\n",
    "    \n",
    "    :return: None. The function generates and displays HTML content side by side for given DataFrames.\n",
    "    \"\"\"\n",
    "    html_str = ''\n",
    "    html_str += f'<h1 style=\"text-align: left; margin-bottom: -15px;\">{super_title}</h1><br>'\n",
    "    html_str += '<div style=\"display: flex;\">'\n",
    "    for df, title in zip(args, chain(titles, cycle(['</br>']))):\n",
    "        html_str += f'<div style=\"margin-right: 20px;\"><h3 style=\"text-align: center;color:#555555;\">{title}</h3>'\n",
    "        html_str += df.to_html().replace('table', 'table style=\"display:inline; margin-right: 20px;\"')\n",
    "        html_str += '</div>'\n",
    "    html_str += '</div>'\n",
    "    display_html(html_str, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d91a720daf9a2",
   "metadata": {},
   "source": [
    "## **🧮 Import Databases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e78aa233134c06e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:16:51.914097Z",
     "start_time": "2024-10-19T23:16:51.455415Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430519, 30) (143507, 30) (387975, 30)\n",
      "(430519, 30) (143507, 30) (387975, 30)\n",
      "(430519, 123) (143507, 123) (387975, 123)\n",
      "\n",
      " (430519,) (143507,)\n",
      " (430519,) (143507,)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------- Importing the dataset -------------------------------------------------\n",
    "# Load the training and validation sets after feature engineering\n",
    "X_train = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/X_train.parquet')\n",
    "X_val = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/X_val.parquet')\n",
    "test_data = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/test_data.parquet')\n",
    "\n",
    "# Load the target variable\n",
    "y_train = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/y_train.parquet').squeeze()   # .squeeze() to convert to Series\n",
    "y_val = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/y_val.parquet').squeeze()\n",
    "\n",
    "# Load the target variable encoded\n",
    "y_train_encoded = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/y_train_encoded.parquet').squeeze()   # .squeeze() to convert to Series\n",
    "y_val_encoded = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/y_val_encoded.parquet').squeeze()\n",
    "\n",
    "# Load the Ordinal encoded data\n",
    "X_train_ordinal_encoded = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/X_train_ordinal_encoded.parquet')\n",
    "X_val_ordinal_encoded = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/X_val_ordinal_encoded.parquet')\n",
    "test_data_ordinal_encoded = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/test_data_ordinal_encoded.parquet')\n",
    "\n",
    "# Load the One-Hot encoded data\n",
    "X_train_ohe = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/X_train_ohe.parquet')\n",
    "X_val_ohe = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/X_val_ohe.parquet')\n",
    "test_data_ohe = pd.read_parquet('data/2ndNotebook/AfterFeatureEngineering/test_data_ohe.parquet')\n",
    "\n",
    "# Check the shape of the training, validation and test data\n",
    "\n",
    "# Check the shape of the training, validation and test data (Features\n",
    "print(X_train.shape, X_val.shape, test_data.shape)\n",
    "print(X_train_ordinal_encoded.shape, X_val_ordinal_encoded.shape, test_data_ordinal_encoded.shape)\n",
    "print(X_train_ohe.shape, X_val_ohe.shape, test_data_ohe.shape)\n",
    "\n",
    "# Check the shape of the training, validation and test data (Target)\n",
    "print('\\n',y_train.shape, y_val.shape)\n",
    "print('',y_train_encoded.shape, y_val_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd71ca18d539bbd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:16:51.947027Z",
     "start_time": "2024-10-19T23:16:51.931810Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the first 2 rows of each dataset\n",
    "# X_train.head(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5400421ca668a5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:16:52.647116Z",
     "start_time": "2024-10-19T23:16:52.631573Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31d35a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430519, 9) (143507, 9) (387975, 9)\n",
      "(430519, 9) (143507, 9) (387975, 9)\n",
      "(430519, 23) (143507, 23) (387975, 23)\n",
      "\n",
      " (430519,) (143507,)\n",
      " (430519,) (143507,)\n"
     ]
    }
   ],
   "source": [
    "# Drop features based on Feature Selection [2nd Notebook]\n",
    "columns_to_drop_ordinal_encoded = [\n",
    "    # Columns to drop based on the 2nd notebook\n",
    "    'Accident Date Day', 'Accident Date Month', 'Accident Date Weekday', 'Accident Date Year',\n",
    "    'Assembly Date Day', 'Assembly Date Weekday', 'Assembly Date Month', 'Assembly Date Year',\n",
    "    'C-2 Date Day', 'C-2 Date Month', 'C-2 Date Weekday', 'Industry Code', 'Number of Dependents',\n",
    "    'Alternative Dispute Resolution', 'Carrier Type Bucket', 'County of Injury', 'COVID-19 Indicator',\n",
    "    'District Name', 'Gender', 'Medical Fee Region', 'WCIO Nature of Injury Bucket'\n",
    "]\n",
    "\n",
    "columns_to_drop_ohe = [\n",
    "    # Columns to drop based on the 2nd notebook and the fact that they are one-hot encoded\n",
    "    'Accident Date Day', 'Accident Date Month', 'Accident Date Weekday', 'Accident Date Year', \n",
    "    'Assembly Date Day', 'Assembly Date Weekday', 'Assembly Date Month', 'Assembly Date Year', \n",
    "    'C-2 Date Day', 'C-2 Date Month',\n",
    "    'C-2 Date Weekday', 'Industry Code', 'Number of Dependents', \"Alternative Dispute Resolution_U\",\n",
    "    \"Alternative Dispute Resolution_Y\", \"County of Injury_ALLEGANY\", \"County of Injury_BRONX\",\n",
    "    \"County of Injury_BROOME\", \"County of Injury_CATTARAUGUS\", \"County of Injury_CAYUGA\", \"County of Injury_CHAUTAUQUA\",\n",
    "    \"County of Injury_CHEMUNG\", \"County of Injury_CHENANGO\", \"County of Injury_CLINTON\", \"County of Injury_COLUMBIA\",\n",
    "    \"County of Injury_CORTLAND\", \"County of Injury_DELAWARE\", \"County of Injury_DUTCHESS\", \"County of Injury_ERIE\",\n",
    "    \"County of Injury_ESSEX\", \"County of Injury_FRANKLIN\", \"County of Injury_FULTON\", \"County of Injury_GENESEE\",\n",
    "    \"County of Injury_GREENE\", \"County of Injury_HAMILTON\", \"County of Injury_HERKIMER\", \"County of Injury_JEFFERSON\",\n",
    "    \"County of Injury_KINGS\", \"County of Injury_LEWIS\", \"County of Injury_LIVINGSTON\", \"County of Injury_MADISON\",\n",
    "    \"County of Injury_MONROE\", \"County of Injury_MONTGOMERY\", \"County of Injury_NASSAU\", \"County of Injury_NEW YORK\",\n",
    "    \"County of Injury_NIAGARA\", \"County of Injury_ONEIDA\", \"County of Injury_ONONDAGA\", \"County of Injury_ONTARIO\",\n",
    "    \"County of Injury_ORANGE\", \"County of Injury_ORLEANS\", \"County of Injury_OSWEGO\", \"County of Injury_OTSEGO\",\n",
    "    \"County of Injury_PUTNAM\", \"County of Injury_QUEENS\", \"County of Injury_RENSSELAER\", \"County of Injury_RICHMOND\",\n",
    "    \"County of Injury_ROCKLAND\", \"County of Injury_SARATOGA\", \"County of Injury_SCHENECTADY\", \"County of Injury_SCHOHARIE\",\n",
    "    \"County of Injury_SCHUYLER\", \"County of Injury_SENECA\", \"County of Injury_ST. LAWRENCE\", \"County of Injury_STEUBEN\",\n",
    "    \"County of Injury_SUFFOLK\", \"County of Injury_SULLIVAN\", \"County of Injury_TIOGA\", \"County of Injury_TOMPKINS\",\n",
    "    \"County of Injury_ULSTER\", \"County of Injury_UNKNOWN\", \"County of Injury_WARREN\", \"County of Injury_WASHINGTON\",\n",
    "    \"County of Injury_WAYNE\", \"County of Injury_WESTCHESTER\", \"County of Injury_WYOMING\", \"County of Injury_YATES\",\n",
    "    \"COVID-19 Indicator_Y\", \"District Name_BINGHAMTON\", \"District Name_BUFFALO\", \"District Name_HAUPPAUGE\",\n",
    "    \"District Name_NYC\", \"District Name_ROCHESTER\", \"District Name_STATEWIDE\", \"District Name_SYRACUSE\", \"Gender_M\",\n",
    "    \"Gender_U\", \"Gender_X\", \"Medical Fee Region_II\", \"Medical Fee Region_III\", \"Medical Fee Region_IV\", \n",
    "    \"Medical Fee Region_UK\", \"Carrier Type Bucket_1A. PRIVATE\", \"Carrier Type Bucket_2A. SIF\",\n",
    "    \"Carrier Type Bucket_3A. SELF PUBLIC\", \"Carrier Type Bucket_4A. SELF PRIVATE\", \"Carrier Type Bucket_5A-5C. SPECIAL FUND\",\n",
    "    \"WCIO Nature of Injury Bucket_1 - Specific\", \"WCIO Nature of Injury Bucket_2 - Occupational/Cumulative\",\n",
    "    \"WCIO Nature of Injury Bucket_3 - Multiple\"\n",
    "]\n",
    "\n",
    "X_train = X_train.drop(columns = columns_to_drop_ordinal_encoded)\n",
    "X_val = X_val.drop(columns = columns_to_drop_ordinal_encoded)\n",
    "test_data = test_data.drop(columns = columns_to_drop_ordinal_encoded)\n",
    "\n",
    "X_train_ordinal_encoded = X_train_ordinal_encoded.drop(columns = columns_to_drop_ordinal_encoded)\n",
    "X_val_ordinal_encoded = X_val_ordinal_encoded.drop(columns = columns_to_drop_ordinal_encoded)\n",
    "test_data_ordinal_encoded = test_data_ordinal_encoded.drop(columns = columns_to_drop_ordinal_encoded)\n",
    "\n",
    "X_train_ohe = X_train_ohe.drop(columns = columns_to_drop_ohe)\n",
    "X_val_ohe = X_val_ohe.drop(columns = columns_to_drop_ohe)\n",
    "test_data_ohe = test_data_ohe.drop(columns = columns_to_drop_ohe)\n",
    "\n",
    "# Check the shape of the training, validation and test data\n",
    "print(X_train.shape, X_val.shape, test_data.shape)\n",
    "print(X_train_ordinal_encoded.shape, X_val_ordinal_encoded.shape, test_data_ordinal_encoded.shape)\n",
    "print(X_train_ohe.shape, X_val_ohe.shape, test_data_ohe.shape)\n",
    "\n",
    "print('\\n',y_train.shape, y_val.shape)\n",
    "print('',y_train_encoded.shape, y_val_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f158b792ebd291",
   "metadata": {},
   "source": [
    "# <a class='anchor' id='3'></a>\n",
    "<br>\n",
    "<style>\n",
    "@import url('https://fonts.cdnfonts.com/css/avenir-next-lt-pro?styles=29974');\n",
    "</style>\n",
    "\n",
    "<div style=\"background: linear-gradient(to right,#08529C, #08306B); \n",
    "            padding: 10px; color: white; border-radius: 300px; text-align: center;\">\n",
    "    <center><h1 style=\"margin-left: 140px;margin-top: 10px; margin-bottom: 4px; color: white;\n",
    "                       font-size: 32px; font-family: 'Avenir Next LT Pro', sans-serif;\">\n",
    "        <b>3 | Modeling & Evaluation</b></h1></center>\n",
    "</div>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714bd8f0747bd46",
   "metadata": {},
   "source": [
    "#### **📈📉 Data Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f06445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry Code</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>C-3 Date Binary</th>\n",
       "      <th>First Hearing Date Binary</th>\n",
       "      <th>Age at Injury Clean</th>\n",
       "      <th>Weekly Wage Reported</th>\n",
       "      <th>IME-4 Reported</th>\n",
       "      <th>Accident Date Year</th>\n",
       "      <th>Accident Date Month</th>\n",
       "      <th>Accident Date Day</th>\n",
       "      <th>Accident Date Weekday</th>\n",
       "      <th>Assembly Date Year</th>\n",
       "      <th>Assembly Date Month</th>\n",
       "      <th>Assembly Date Day</th>\n",
       "      <th>Assembly Date Weekday</th>\n",
       "      <th>C-2 Date Year</th>\n",
       "      <th>C-2 Date Month</th>\n",
       "      <th>C-2 Date Day</th>\n",
       "      <th>C-2 Date Weekday</th>\n",
       "      <th>Alternative Dispute Resolution</th>\n",
       "      <th>Attorney/Representative</th>\n",
       "      <th>County of Injury</th>\n",
       "      <th>COVID-19 Indicator</th>\n",
       "      <th>District Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medical Fee Region</th>\n",
       "      <th>Carrier Type Bucket</th>\n",
       "      <th>WCIO Cause of Injury Bucket</th>\n",
       "      <th>WCIO Nature of Injury Bucket</th>\n",
       "      <th>WCIO Part of Body Bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "      <td>430519.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.631182</td>\n",
       "      <td>3.005159</td>\n",
       "      <td>0.673975</td>\n",
       "      <td>0.737273</td>\n",
       "      <td>42.582813</td>\n",
       "      <td>0.365910</td>\n",
       "      <td>0.231734</td>\n",
       "      <td>2020.827917</td>\n",
       "      <td>6.495885</td>\n",
       "      <td>15.523336</td>\n",
       "      <td>2.498415</td>\n",
       "      <td>2021.051858</td>\n",
       "      <td>6.490167</td>\n",
       "      <td>15.653757</td>\n",
       "      <td>2.009189</td>\n",
       "      <td>2021.041649</td>\n",
       "      <td>6.479233</td>\n",
       "      <td>15.668583</td>\n",
       "      <td>2.146722</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.316325</td>\n",
       "      <td>30.392642</td>\n",
       "      <td>0.047914</td>\n",
       "      <td>3.337846</td>\n",
       "      <td>0.600545</td>\n",
       "      <td>1.957430</td>\n",
       "      <td>1.897212</td>\n",
       "      <td>5.550238</td>\n",
       "      <td>1.087545</td>\n",
       "      <td>3.748190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.921418</td>\n",
       "      <td>1.999966</td>\n",
       "      <td>0.468757</td>\n",
       "      <td>0.440116</td>\n",
       "      <td>13.720364</td>\n",
       "      <td>0.481685</td>\n",
       "      <td>0.421941</td>\n",
       "      <td>1.857243</td>\n",
       "      <td>3.456475</td>\n",
       "      <td>8.750192</td>\n",
       "      <td>1.808353</td>\n",
       "      <td>0.810441</td>\n",
       "      <td>3.445363</td>\n",
       "      <td>8.734030</td>\n",
       "      <td>1.437552</td>\n",
       "      <td>1.091358</td>\n",
       "      <td>3.428433</td>\n",
       "      <td>8.644747</td>\n",
       "      <td>1.458968</td>\n",
       "      <td>0.133807</td>\n",
       "      <td>0.465042</td>\n",
       "      <td>16.572761</td>\n",
       "      <td>0.213585</td>\n",
       "      <td>1.878883</td>\n",
       "      <td>0.506595</td>\n",
       "      <td>1.337976</td>\n",
       "      <td>1.045697</td>\n",
       "      <td>2.492914</td>\n",
       "      <td>0.423840</td>\n",
       "      <td>1.587845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1961.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Industry Code  Number of Dependents  C-3 Date Binary  \\\n",
       "count  430519.000000         430519.000000    430519.000000   \n",
       "mean       57.631182              3.005159         0.673975   \n",
       "std        20.921418              1.999966         0.468757   \n",
       "min         0.000000              0.000000         0.000000   \n",
       "25%        44.000000              1.000000         0.000000   \n",
       "50%        61.000000              3.000000         1.000000   \n",
       "75%        62.000000              5.000000         1.000000   \n",
       "max        92.000000              6.000000         1.000000   \n",
       "\n",
       "       First Hearing Date Binary  Age at Injury Clean  Weekly Wage Reported  \\\n",
       "count              430519.000000        430519.000000         430519.000000   \n",
       "mean                    0.737273            42.582813              0.365910   \n",
       "std                     0.440116            13.720364              0.481685   \n",
       "min                     0.000000             1.000000              0.000000   \n",
       "25%                     0.000000            31.000000              0.000000   \n",
       "50%                     1.000000            42.000000              0.000000   \n",
       "75%                     1.000000            54.000000              1.000000   \n",
       "max                     1.000000           122.000000              1.000000   \n",
       "\n",
       "       IME-4 Reported  Accident Date Year  Accident Date Month  \\\n",
       "count   430519.000000       430519.000000        430519.000000   \n",
       "mean         0.231734         2020.827917             6.495885   \n",
       "std          0.421941            1.857243             3.456475   \n",
       "min          0.000000         1961.000000             1.000000   \n",
       "25%          0.000000         2020.000000             3.000000   \n",
       "50%          0.000000         2021.000000             7.000000   \n",
       "75%          0.000000         2022.000000             9.000000   \n",
       "max          1.000000         2023.000000            12.000000   \n",
       "\n",
       "       Accident Date Day  Accident Date Weekday  Assembly Date Year  \\\n",
       "count      430519.000000          430519.000000       430519.000000   \n",
       "mean           15.523336               2.498415         2021.051858   \n",
       "std             8.750192               1.808353            0.810441   \n",
       "min             1.000000               0.000000         2020.000000   \n",
       "25%             8.000000               1.000000         2020.000000   \n",
       "50%            15.000000               2.000000         2021.000000   \n",
       "75%            23.000000               4.000000         2022.000000   \n",
       "max            31.000000               6.000000         2022.000000   \n",
       "\n",
       "       Assembly Date Month  Assembly Date Day  Assembly Date Weekday  \\\n",
       "count        430519.000000      430519.000000          430519.000000   \n",
       "mean              6.490167          15.653757               2.009189   \n",
       "std               3.445363           8.734030               1.437552   \n",
       "min               1.000000           1.000000               0.000000   \n",
       "25%               3.000000           8.000000               1.000000   \n",
       "50%               7.000000          16.000000               2.000000   \n",
       "75%               9.000000          23.000000               3.000000   \n",
       "max              12.000000          31.000000               6.000000   \n",
       "\n",
       "       C-2 Date Year  C-2 Date Month   C-2 Date Day  C-2 Date Weekday  \\\n",
       "count  430519.000000   430519.000000  430519.000000     430519.000000   \n",
       "mean     2021.041649        6.479233      15.668583          2.146722   \n",
       "std         1.091358        3.428433       8.644747          1.458968   \n",
       "min      1996.000000        1.000000       1.000000          0.000000   \n",
       "25%      2020.000000        3.000000       8.000000          1.000000   \n",
       "50%      2021.000000        7.000000      16.000000          2.000000   \n",
       "75%      2022.000000        9.000000      23.000000          3.000000   \n",
       "max      2024.000000       12.000000      31.000000          6.000000   \n",
       "\n",
       "       Alternative Dispute Resolution  Attorney/Representative  \\\n",
       "count                   430519.000000            430519.000000   \n",
       "mean                         0.008996                 0.316325   \n",
       "std                          0.133807                 0.465042   \n",
       "min                          0.000000                 0.000000   \n",
       "25%                          0.000000                 0.000000   \n",
       "50%                          0.000000                 0.000000   \n",
       "75%                          0.000000                 1.000000   \n",
       "max                          2.000000                 1.000000   \n",
       "\n",
       "       County of Injury  COVID-19 Indicator  District Name         Gender  \\\n",
       "count     430519.000000       430519.000000  430519.000000  430519.000000   \n",
       "mean          30.392642            0.047914       3.337846       0.600545   \n",
       "std           16.572761            0.213585       1.878883       0.506595   \n",
       "min            0.000000            0.000000       0.000000       0.000000   \n",
       "25%           21.000000            0.000000       2.000000       0.000000   \n",
       "50%           30.000000            0.000000       4.000000       1.000000   \n",
       "75%           42.000000            0.000000       4.000000       1.000000   \n",
       "max           62.000000            1.000000       7.000000       3.000000   \n",
       "\n",
       "       Medical Fee Region  Carrier Type Bucket  WCIO Cause of Injury Bucket  \\\n",
       "count       430519.000000        430519.000000                430519.000000   \n",
       "mean             1.957430             1.897212                     5.550238   \n",
       "std              1.337976             1.045697                     2.492914   \n",
       "min              0.000000             0.000000                     0.000000   \n",
       "25%              1.000000             1.000000                     4.000000   \n",
       "50%              3.000000             1.000000                     5.000000   \n",
       "75%              3.000000             3.000000                     7.000000   \n",
       "max              4.000000             5.000000                    10.000000   \n",
       "\n",
       "       WCIO Nature of Injury Bucket  WCIO Part of Body Bucket  \n",
       "count                 430519.000000             430519.000000  \n",
       "mean                       1.087545                  3.748190  \n",
       "std                        0.423840                  1.587845  \n",
       "min                        0.000000                  0.000000  \n",
       "25%                        1.000000                  3.000000  \n",
       "50%                        1.000000                  4.000000  \n",
       "75%                        1.000000                  5.000000  \n",
       "max                        3.000000                  6.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics of the training data after feature engineering (Ordinal Encoded)\n",
    "X_train_ordinal_encoded.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c152f0c",
   "metadata": {},
   "source": [
    "> For **Modeling & Evaluation**, we will normalize the data using the **`StandardScaler`**, **`MinMaxScaler`**, and **`Log`** methods, to evaluate the best performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2292870599c6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:17:01.202515Z",
     "start_time": "2024-10-19T23:17:01.199653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize the data [For the 'KNN' and 'Logistic Regression' models, let's normalize the variables]\n",
    "standard_scaler = StandardScaler().fit(X_train_ordinal_encoded)\n",
    "X_train_standardized = standard_scaler.transform(X_train_ordinal_encoded)\n",
    "X_validation_standardized = standard_scaler.transform(X_val_ordinal_encoded)\n",
    "X_test_standardized = standard_scaler.transform(test_data_ordinal_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e46b60f81b4152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:17:02.929224Z",
     "start_time": "2024-10-19T23:17:02.523447Z"
    }
   },
   "outputs": [],
   "source": [
    "# Min-Max Normalization\n",
    "minmax_scaler = MinMaxScaler().fit(X_train_ordinal_encoded)\n",
    "X_train_norm = minmax_scaler.transform(X_train_ordinal_encoded)\n",
    "X_validation_norm = minmax_scaler.transform(X_val_ordinal_encoded)\n",
    "X_test_norm = minmax_scaler.transform(test_data_ordinal_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformation - Logarithm of the values in the dataset (Base 10)\n",
    "# Since log(0) is undefined, we will apply the log in the dataset where the values are greater than 0 and replace the NaN values with 0\n",
    "X_train_log = X_train_ordinal_encoded.where(X_train_ordinal_encoded > 0).apply(np.log).replace(np.nan, 0)\n",
    "X_validation_log = X_val_ordinal_encoded.where(X_val_ordinal_encoded > 0).apply(np.log).replace(np.nan, 0)\n",
    "X_test_log = test_data_ordinal_encoded.where(test_data_ordinal_encoded > 0).apply(np.log).replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa9f29",
   "metadata": {},
   "source": [
    "> With the **$log$ transformation**, the key goal is to reduce the skewness of the variables $\\rightarrow$ this changes the variable's own distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Boxplots of Original Data, Standardized Data, Normalized Data, and Log Transformation for Train, Validation, and Test Sets\n",
    "fig, ax = plt.subplots(3, 4, figsize=(24, 15))  # 3 rows for Train, Validation, Test and 4 columns for each transformation\n",
    "\n",
    "# Define titles for rows\n",
    "row_titles = ['Training Data', 'Validation Data', 'Test Data']\n",
    "\n",
    "# Original Data - Train, Validation, Test\n",
    "X_train_ordinal_encoded.boxplot(ax=ax[0, 0], color='#002147')\n",
    "X_val_ordinal_encoded.boxplot(ax=ax[1, 0], color='#002147')\n",
    "test_data_ordinal_encoded.boxplot(ax=ax[2, 0], color='#002147')\n",
    "ax[0, 0].set_title('Original Data', fontsize=16, fontweight='bold')\n",
    "ax[0, 0].set_xticks([])\n",
    "\n",
    "# Standardized Data - Train, Validation, Test\n",
    "pd.DataFrame(X_train_standardized, columns=X_train_ordinal_encoded.columns).boxplot(ax=ax[0, 1], color='#135C9B')\n",
    "pd.DataFrame(X_validation_standardized, columns=X_train_ordinal_encoded.columns).boxplot(ax=ax[1, 1], color='#135C9B')\n",
    "pd.DataFrame(X_test_standardized, columns=X_train_ordinal_encoded.columns).boxplot(ax=ax[2, 1], color='#135C9B')\n",
    "ax[0, 1].set_title('Standardized Data | N(0, 1)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Normalized Data - Train, Validation, Test\n",
    "pd.DataFrame(X_train_norm, columns=X_train_ordinal_encoded.columns).boxplot(ax=ax[0, 2], color='#4292C6')\n",
    "pd.DataFrame(X_validation_norm, columns=X_train_ordinal_encoded.columns).boxplot(ax=ax[1, 2], color='#4292C6')\n",
    "pd.DataFrame(X_test_norm, columns=X_train_ordinal_encoded.columns).boxplot(ax=ax[2, 2], color='#4292C6')\n",
    "ax[0, 2].set_title('Normalized Data | [0,1]', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Log Transformation - Train, Validation, Test\n",
    "pd.DataFrame(X_train_log, columns=X_train_ordinal_encoded.columns).boxplot(ax=ax[0, 3], color='#6BAED6')\n",
    "pd.DataFrame(X_validation_log, columns=X_train_ordinal_encoded.columns).boxplot(ax=ax[1, 3], color='#6BAED6')\n",
    "pd.DataFrame(X_test_log, columns=X_train_ordinal_encoded.columns).boxplot(ax=ax[2, 3], color='#6BAED6')\n",
    "ax[0, 3].set_title('Log Transformation', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Adjust x-ticks rotation and y-labels\n",
    "for row in range(3):\n",
    "    for col in range(4):\n",
    "        ax[row, col].tick_params(axis='x', rotation=90, labelsize=8)\n",
    "    ax[row, 0].set_ylabel(f'{row_titles[row]}\\n', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Despine and adjust layout\n",
    "sns.despine(top=True, right=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./[ML]_Project_EDAOutputs_Group33/Modeling/Boxplots_ScalersTransformations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff83fd3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9446fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since OHE make categorical variables binary [0,1], we can apply the MinMaxScaler to the One-Hot encoded data\n",
    "# We will mantain the same interval [0,1] for categorical variables and make the numerical variables in the same scale\n",
    "minmax_scaler = MinMaxScaler().fit(X_train_ohe)\n",
    "X_train_ohe_norm = pd.DataFrame(minmax_scaler.transform(X_train_ohe),\n",
    "                                columns = X_train_ohe.columns,\n",
    "                                index = X_train_ohe.index)\n",
    "X_validation_ohe_norm = pd.DataFrame(minmax_scaler.transform(X_val_ohe),\n",
    "                                    columns = X_val_ohe.columns,\n",
    "                                    index = X_val_ohe.index)\n",
    "X_test_ohe_norm = pd.DataFrame(minmax_scaler.transform(test_data_ohe),\n",
    "                               columns = test_data_ohe.columns,\n",
    "                               index = test_data_ohe.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ddabe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26312ae5b0368022",
   "metadata": {},
   "source": [
    "# **💡 Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a184937",
   "metadata": {},
   "source": [
    "### **Definition of the Problem**\n",
    "\n",
    "> The problem consists of predict the WCB’s final decision on what type of injury (Claim Injury Type) should be granted. <br>\n",
    "> Since the target variable is **category** and **multiclass**, we will use **Classification Models** to solve this problem.\n",
    "\n",
    "> Since we have a **Classification Problem**, we will use the following metrics to evaluate the models:\n",
    "\n",
    "- **Accuracy**: The proportion of true results among the total number of cases examined.\n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}} $$\n",
    "\n",
    "- **Precision**: The proportion of true positive results among the positive results predicted by the model.\n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $$\n",
    "\n",
    "- **Recall**\n",
    "- **F1-Score (Macro)**\n",
    "- **Confusion Matrix**\n",
    "- **ROC Curve**\n",
    "- **AUC Score**\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 30px; font-weight: bold; text-align: center;\">\n",
    "    \n",
    "> FAZER ISTO\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62931543e5893c7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:39:02.675792Z",
     "start_time": "2024-10-19T23:39:02.667470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function that will print the results of the classification report and the confusion matrix for both datasets (train and validation)\n",
    "# Additionally, it will save results in a dictionary to compare the results of different models\n",
    "\n",
    "models_results_train = {}\n",
    "models_results_val = {}\n",
    "\n",
    "def classification_metrics(model_name, cv_results,\n",
    "                           y_train, pred_train, pred_train_proba, \n",
    "                           y_val, pred_val, pred_val_proba, classification_report=True):\n",
    "    \n",
    "    # Display model name\n",
    "    display_html(f'<h1 style=\"text-align: left; margin-bottom: -15px;\">{model_name}</h1><br>', raw=True)\n",
    "\n",
    "    # Display the results of the cross-validation (KFold) - If classification_report=True\n",
    "    if classification_report:\n",
    "        # ------------------------------------- Classification Report  -------------------------------------\n",
    "        print('___________________________________________________________________________________________________________')\n",
    "        print('                                                     TRAIN                                                 ')\n",
    "        print('-----------------------------------------------------------------------------------------------------------')\n",
    "        print(classification_report(y_train, pred_train, target_names=[str(i) for i in np.unique(y_train)], zero_division=1))  \n",
    "        # zero_division=1 to avoid warnings -> y_true contains labels that are not present in your predictions (y_pred)\n",
    "        print('\\nAUROC:', round(roc_auc_score(y_train, pred_train_proba, multi_class='ovr'), 2)) # 'ovr' for multiclass\n",
    "\n",
    "        print('___________________________________________________________________________________________________________')\n",
    "        print('                                                VALIDATION                                                 ')\n",
    "        print('-----------------------------------------------------------------------------------------------------------')\n",
    "        print(classification_report(y_val, pred_val, target_names=[str(i) for i in np.unique(y_val)], zero_division=1))\n",
    "        print('\\nAUROC:', round(roc_auc_score(y_val, pred_val_proba, multi_class='ovr'), 2))  # 'ovr' for multiclass\n",
    "    \n",
    "    # ----------------------------------- Confusion Matrix for Train and Validation side by side -----------------------------------\n",
    "\n",
    "    # Confusion Matrix for Train and Validation side by side\n",
    "    fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "    sns.heatmap(confusion_matrix(y_train, pred_train, labels=np.unique(y_val)),\n",
    "                annot=True, annot_kws={\"size\": 7}, \n",
    "                fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=np.unique(y_val), yticklabels=np.unique(y_val), ax=ax[0])\n",
    "    ax[0].set_title('Confusion Matrix [Train]\\n', fontsize=12, fontweight='bold')\n",
    "    ax[0].set_xlabel('\\nPredicted', fontsize=8, fontweight='bold')\n",
    "    ax[0].set_yticklabels(labels=np.unique(y_val), rotation=0)\n",
    "    ax[0].set_ylabel('True\\n', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    sns.heatmap(confusion_matrix(y_val, pred_val, labels=np.unique(y_val)),\n",
    "                annot=True, annot_kws={\"size\": 7},\n",
    "                fmt='d', cmap='Blues', cbar=False, \n",
    "                xticklabels=np.unique(y_val), yticklabels=np.unique(y_val),ax=ax[1])\n",
    "    ax[1].set_title('Confusion Matrix [Validation]\\n', fontsize=12, fontweight='bold')\n",
    "    ax[1].set_xlabel('\\nPredicted', fontsize=8, fontweight='bold')\n",
    "    ax[1].set_yticklabels(labels=np.unique(y_val), rotation=0)\n",
    "    ax[1].set_ylabel('True\\n', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ----------------------------------- Save the results in a dictionary -----------------------------------\n",
    "    # List of All Metrics for Classification Problems - Accuracy, Precision, Recall, F1 Score Macro (Kaggle Bechmark), ROC-AUC\n",
    "    models_results_train[model_name] = {\n",
    "        'Time of Execution (KFold)': str(cv_results['fit_time'].sum().round(2)) + ' +/-' + str(round(np.std(np.array(cv_results['fit_time'])), 2)),\n",
    "        'Accuracy': round(accuracy_score(y_train, pred_train), 2),\n",
    "        'Precision': round(metrics.precision_score(y_train, pred_train, average='macro', zero_division=np.nan), 2),\n",
    "        'Recall': round(metrics.recall_score(y_train, pred_train, average='macro'), 2),\n",
    "        'F1 Score': round(metrics.f1_score(y_train, pred_train, average='macro'), 2),\n",
    "        'AUROC': round(roc_auc_score(y_train, pred_train_proba, multi_class='ovr'), 2)\n",
    "    }\n",
    "\n",
    "    models_results_val[model_name] = {\n",
    "        'Accuracy': round(accuracy_score(y_val, pred_val), 2),\n",
    "        'Precision': round(metrics.precision_score(y_val, pred_val, average='macro', zero_division=np.nan), 2),\n",
    "        'Recall': round(metrics.recall_score(y_val, pred_val, average='macro'), 2),\n",
    "        'F1 Score': round(metrics.f1_score(y_val, pred_val, average='macro'), 2),\n",
    "        'AUROC': round(roc_auc_score(y_val, pred_val_proba, multi_class='ovr'), 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5750e0c9099e4cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e911fc9f991fab36",
   "metadata": {},
   "source": [
    "### **Logistic Regression [<sup>[1]</sup>](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html)** <a class='anchor' id='logistic-regression'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98810ca06c5c9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:52:36.279430Z",
     "start_time": "2024-10-19T23:51:29.642034Z"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------- Logistic Regression -------------------------------------------------\n",
    "# ################################ Ordinal Encoding (with and without Standardization)\n",
    "# ============ Original Data\n",
    "lr_ord = LogisticRegression()\n",
    "lr_cv_ord = cross_validate(lr_ord,X_train_ordinal_encoded,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "lr_ord.fit(X_train_norm, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_ord_pred_train = lr_ord.predict(X_train_norm)\n",
    "lr_ord_pred_train_proba = lr_ord.predict_proba(X_train_norm)\n",
    "\n",
    "lr_ord_pred_val = lr_ord.predict(X_val_ordinal_encoded)\n",
    "lr_ord_pred_val_proba = lr_ord.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ============ With Standardization\n",
    "lr_ord_std = LogisticRegression()\n",
    "lr_cv_ord_std = cross_validate(lr_ord_std,X_train_standardized,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "lr_ord_std.fit(X_train_standardized, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_ord_std_pred_train = lr_ord_std.predict(X_train_standardized)\n",
    "lr_ord_std_pred_train_proba = lr_ord_std.predict_proba(X_train_standardized)\n",
    "\n",
    "lr_ord_std_pred_val = lr_ord_std.predict(X_validation_standardized)\n",
    "lr_ord_std_pred_val_proba = lr_ord_std.predict_proba(X_validation_standardized)\n",
    "\n",
    "\n",
    "# ============ With Normalization\n",
    "lr_ord_norm = LogisticRegression()\n",
    "lr_cv_ord_norm = cross_validate(lr_ord_norm,X_train_norm,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "lr_ord_norm.fit(X_train_norm, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_ord_norm_pred_train = lr_ord_norm.predict(X_train_norm)\n",
    "lr_ord_norm_pred_train_proba = lr_ord_norm.predict_proba(X_train_norm)\n",
    "\n",
    "lr_ord_norm_pred_val = lr_ord_norm.predict(X_val_ordinal_encoded)\n",
    "lr_ord_norm_pred_val_proba = lr_ord_norm.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ============ With Log Transformation\n",
    "lr_ord_log = LogisticRegression()\n",
    "lr_cv_ord_log = cross_validate(lr_ord_log,X_train_log,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "lr_ord_log.fit(X_train_log, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_ord_log_pred_train = lr_ord_log.predict(X_train_log)\n",
    "lr_ord_log_pred_train_proba = lr_ord_log.predict_proba(X_train_log)\n",
    "\n",
    "lr_ord_log_pred_val = lr_ord_log.predict(X_val_ordinal_encoded)\n",
    "lr_ord_log_pred_val_proba = lr_ord_log.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ################################ One-Hot Encoding\n",
    "lr_ohe = LogisticRegression()\n",
    "lr_cv_ohe = cross_validate(lr_ohe,X_train_ohe,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "lr_ohe.fit(X_train_ohe, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_ohe_pred_train = lr_ohe.predict(X_train_ohe)\n",
    "lr_ohe_pred_train_proba = lr_ohe.predict_proba(X_train_ohe)\n",
    "\n",
    "lr_ohe_pred_val = lr_ohe.predict(X_val_ohe)\n",
    "lr_ohe_pred_val_proba = lr_ohe.predict_proba(X_val_ohe)\n",
    "\n",
    "## Time of Execution Logistic Regression = 6m 34.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc077bdc8c39898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:33:07.347613Z",
     "start_time": "2024-10-19T23:33:05.281897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classification Metrics & Confusion Matrix\n",
    "classification_metrics('Logistic Regression | Ordinal Encoding (Original Data)', lr_cv_ord,\n",
    "                       y_train, lr_ord_pred_train, lr_ord_pred_train_proba, \n",
    "                       y_val, lr_ord_pred_val, lr_ord_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('Logistic Regression | Ordinal Encoding (With Standardization)', lr_cv_ord_std,\n",
    "                        y_train, lr_ord_std_pred_train, lr_ord_std_pred_train_proba, \n",
    "                        y_val, lr_ord_std_pred_val, lr_ord_std_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('Logistic Regression | Ordinal Encoding (With Normalization)', lr_cv_ord_norm,\n",
    "                        y_train, lr_ord_norm_pred_train, lr_ord_norm_pred_train_proba, \n",
    "                        y_val, lr_ord_norm_pred_val, lr_ord_norm_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('Logistic Regression | Ordinal Encoding (With Log Transformation)', lr_cv_ord_log,\n",
    "                        y_train, lr_ord_log_pred_train, lr_ord_log_pred_train_proba, \n",
    "                        y_val, lr_ord_log_pred_val, lr_ord_log_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('Logistic Regression | One-Hot Encoding', lr_cv_ohe,\n",
    "                        y_train, lr_ohe_pred_train, lr_ohe_pred_train_proba, \n",
    "                        y_val, lr_ohe_pred_val, lr_ohe_pred_val_proba, classification_report=False)\n",
    "\n",
    "##############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with the results of the models\n",
    "df_results_train = pd.DataFrame(models_results_train).T\n",
    "df_results_val = pd.DataFrame(models_results_val).T\n",
    "\n",
    "# Display the results\n",
    "display_side_by_side(df_results_train, df_results_val, \n",
    "                     titles=['Training Set', 'Validation Set'],\n",
    "                     super_title='Results of the Logistic Regression Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5d6f6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767babb4472cb7e4",
   "metadata": {},
   "source": [
    "### **Naive Bayes [<sup>[2]</sup>](https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html)** <a class='anchor' id='naive-bayes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a48e7d",
   "metadata": {},
   "source": [
    "> For the Naive Bayes model, we will use two different approaches: **Categorical** and **Gaussian**.\n",
    "> - **Categorical**: This model is used when the features are categorical.\n",
    "> - **Gaussian**: This model is used when the features are continuous.\n",
    "\n",
    "\n",
    "> In this case, we will don't modeling with the Standardized/Normalized/Log-transformed Data, since the **Naive Bayes model doesn't require it**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc56f5",
   "metadata": {},
   "source": [
    "#### **Naive Bayes - Categorical** <sup>[**[2.1]**](https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.CategoricalNB.html)</sup> <a class='anchor' id='naive-bayes-categorical'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84de8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- Naïve Bayes [CategoricalNB] -------------------------------------------------\n",
    "# ################################ Ordinal Encoding \n",
    "# ============ Original Data\n",
    "nb_ord = CategoricalNB()\n",
    "nb_cv_ord = cross_validate(nb_ord,X_train_ordinal_encoded,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "nb_ord.fit(X_train_ordinal_encoded, y_train)\n",
    "\n",
    "# Predictions\n",
    "nb_ord_pred_train = nb_ord.predict(X_train_ordinal_encoded)\n",
    "nb_ord_pred_train_proba = nb_ord.predict_proba(X_train_ordinal_encoded)\n",
    "\n",
    "nb_ord_pred_val = nb_ord.predict(X_val_ordinal_encoded)\n",
    "nb_ord_pred_val_proba = nb_ord.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ============ One-Hot Encoding\n",
    "nb_ohe = CategoricalNB()\n",
    "nb_cv_ohe = cross_validate(nb_ohe,X_train_ohe,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "nb_ohe.fit(X_train_ohe, y_train)\n",
    "\n",
    "# Predictions\n",
    "nb_ohe_pred_train = nb_ohe.predict(X_train_ohe)\n",
    "nb_ohe_pred_train_proba = nb_ohe.predict_proba(X_train_ohe)\n",
    "\n",
    "nb_ohe_pred_val = nb_ohe.predict(X_val_ohe)\n",
    "nb_ohe_pred_val_proba = nb_ohe.predict_proba(X_val_ohe)\n",
    "\n",
    "## Time of Execution Naïve Bayes [CategoricalNB] = Xm Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750aa8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Metrics & Confusion Matrix\n",
    "classification_metrics('Naïve Bayes [CategoricalNB] | Ordinal Encoding (Original Data)', nb_cv_ord,\n",
    "                       y_train, nb_ord_pred_train, nb_ord_pred_train_proba, \n",
    "                       y_val, nb_ord_pred_val, nb_ord_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('Naïve Bayes [CategoricalNB] | One-Hot Encoding', nb_cv_ohe,\n",
    "                        y_train, nb_ohe_pred_train, nb_ohe_pred_train_proba, \n",
    "                        y_val, nb_ohe_pred_val, nb_ohe_pred_val_proba, classification_report=False)\n",
    "\n",
    "# Dataframe with the results of the models\n",
    "df_results_train = pd.DataFrame(models_results_train).T\n",
    "df_results_val = pd.DataFrame(models_results_val).T\n",
    "\n",
    "# Display the results\n",
    "display_side_by_side(df_results_train, df_results_val,\n",
    "                     titles=['Training Set', 'Validation Set'],\n",
    "                     super_title='Results of the Naïve Bayes [CategoricalNB] Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf95f1",
   "metadata": {},
   "source": [
    "#### **Naive Bayes - Gaussian** <sup>[**[2.2]**](https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html)</sup> <a class='anchor' id='naive-bayes-gaussian'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937a6b7381a379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:41:28.661361Z",
     "start_time": "2024-10-19T23:41:23.317699Z"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------- Naïve Bayes [GaussianNB] -------------------------------------------------\n",
    "# ################################ Ordinal Encoding\n",
    "# ============ Original Data\n",
    "gnb_ord = GaussianNB(var_smoothing=0.0001)\n",
    "gnb_cv_ord = cross_validate(gnb_ord,X_train_ordinal_encoded,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "gnb_ord.fit(X_train_ordinal_encoded, y_train)\n",
    "\n",
    "# Predictions\n",
    "gnb_ord_pred_train = gnb_ord.predict(X_train_ordinal_encoded)\n",
    "gnb_ord_pred_train_proba = gnb_ord.predict_proba(X_train_ordinal_encoded)\n",
    "\n",
    "gnb_ord_pred_val = gnb_ord.predict(X_val_ordinal_encoded)\n",
    "gnb_ord_pred_val_proba = gnb_ord.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ################################ One-Hot Encoding\n",
    "gnb_ohe = GaussianNB(var_smoothing=0.0001)\n",
    "gnb_cv_ohe = cross_validate(gnb_ohe,X_train_ohe,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "gnb_ohe.fit(X_train_ohe, y_train)\n",
    "\n",
    "# Predictions\n",
    "gnb_ohe_pred_train = gnb_ohe.predict(X_train_ohe)\n",
    "gnb_ohe_pred_train_proba = gnb_ohe.predict_proba(X_train_ohe)\n",
    "\n",
    "gnb_ohe_pred_val = gnb_ohe.predict(X_val_ohe)\n",
    "gnb_ohe_pred_val_proba = gnb_ohe.predict_proba(X_val_ohe)\n",
    "\n",
    "## Time of Execution Naïve Bayes [GaussianNB] = 29.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e4886c3866948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:41:30.907980Z",
     "start_time": "2024-10-19T23:41:28.669880Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classification Metrics & Confusion Matrix\n",
    "classification_metrics('Naïve Bayes [GaussianNB] | Ordinal Encoding (Original Data)', gnb_cv_ord,\n",
    "                       y_train, gnb_ord_pred_train, gnb_ord_pred_train_proba, \n",
    "                       y_val, gnb_ord_pred_val, gnb_ord_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('Naïve Bayes [GaussianNB] | One-Hot Encoding', gnb_cv_ohe,\n",
    "                        y_train, gnb_ohe_pred_train, gnb_ohe_pred_train_proba, \n",
    "                        y_val, gnb_ohe_pred_val, gnb_ohe_pred_val_proba, classification_report=False)\n",
    "\n",
    "# Dataframe with the results of the models\n",
    "df_results_train = pd.DataFrame(models_results_train).T\n",
    "df_results_val = pd.DataFrame(models_results_val).T\n",
    "\n",
    "# Display the results\n",
    "display_side_by_side(df_results_train, df_results_val,\n",
    "                     titles=['Training Set', 'Validation Set'],\n",
    "                     super_title='Results of the Naïve Bayes [GaussianNB] Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1668825",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983890a7217565d3",
   "metadata": {},
   "source": [
    "### **K-Nearest Neighbors (KNN) [<sup>[3]</sup>](https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)** <a class='anchor' id='knn'></a>\n",
    "\n",
    "#### **KNN - Brute Force** <sup>[**[3.1]**](https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.NearestNeighbors.html)</sup> <a class='anchor' id='knn-brute-force'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6e0e1dff3ef20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:51:29.596468Z",
     "start_time": "2024-10-19T23:42:22.572686Z"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------- K-Nearest Neighbors [Brute Force Algorithm] -------------------------------------------------\n",
    "# ################################ Ordinal Encoding\n",
    "# ============ Original Data\n",
    "knn_ord = KNeighborsClassifier(algorithm='brute')\n",
    "knn_cv_ord = cross_validate(knn_ord,X_train_ordinal_encoded,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord.fit(X_train_ordinal_encoded, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_pred_train = knn_ord.predict(X_train_ordinal_encoded)\n",
    "knn_ord_pred_train_proba = knn_ord.predict_proba(X_train_ordinal_encoded)\n",
    "\n",
    "knn_ord_pred_val = knn_ord.predict(X_val_ordinal_encoded)\n",
    "knn_ord_pred_val_proba = knn_ord.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ============ With Standardization\n",
    "knn_ord_std = KNeighborsClassifier(algorithm='brute')\n",
    "knn_cv_ord_std = cross_validate(knn_ord_std,X_train_standardized,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_std.fit(X_train_standardized, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_std_pred_train = knn_ord_std.predict(X_train_standardized)\n",
    "knn_ord_std_pred_train_proba = knn_ord_std.predict_proba(X_train_standardized)\n",
    "\n",
    "knn_ord_std_pred_val = knn_ord_std.predict(X_validation_standardized)\n",
    "knn_ord_std_pred_val_proba = knn_ord_std.predict_proba(X_validation_standardized)\n",
    "\n",
    "# ============ With Normalization\n",
    "knn_ord_norm = KNeighborsClassifier(algorithm='brute')\n",
    "knn_cv_ord_norm = cross_validate(knn_ord_norm,X_train_norm,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_norm.fit(X_train_norm, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_norm_pred_train = knn_ord_norm.predict(X_train_norm)\n",
    "knn_ord_norm_pred_train_proba = knn_ord_norm.predict_proba(X_train_norm)\n",
    "\n",
    "knn_ord_norm_pred_val = knn_ord_norm.predict(X_val_ordinal_encoded)\n",
    "knn_ord_norm_pred_val_proba = knn_ord_norm.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ============ With Log Transformation\n",
    "knn_ord_log = KNeighborsClassifier(algorithm='brute')\n",
    "knn_cv_ord_log = cross_validate(knn_ord_log,X_train_log,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_log.fit(X_train_log, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_log_pred_train = knn_ord_log.predict(X_train_log)\n",
    "knn_ord_log_pred_train_proba = knn_ord_log.predict_proba(X_train_log)\n",
    "\n",
    "knn_ord_log_pred_val = knn_ord_log.predict(X_val_ordinal_encoded)\n",
    "knn_ord_log_pred_val_proba = knn_ord_log.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ################################ One-Hot Encoding\n",
    "knn_ohe = KNeighborsClassifier(algorithm='brute')\n",
    "knn_cv_ohe = cross_validate(knn_ohe,X_train_ohe,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ohe.fit(X_train_ohe, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ohe_pred_train = knn_ohe.predict(X_train_ohe)\n",
    "knn_ohe_pred_train_proba = knn_ohe.predict_proba(X_train_ohe)\n",
    "\n",
    "knn_ohe_pred_val = knn_ohe.predict(X_val_ohe)\n",
    "knn_ohe_pred_val_proba = knn_ohe.predict_proba(X_val_ohe)\n",
    "\n",
    "## Time of Execution KNN (Brute Force Algorithm) = 40m 47.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Metrics & Confusion Matrix\n",
    "classification_metrics('K-Nearest Neighbors [Brute Force Algorithm] | Ordinal Encoding (Original Data)', knn_cv_ord,\n",
    "                       y_train, knn_ord_pred_train, knn_ord_pred_train_proba, \n",
    "                       y_val, knn_ord_pred_val, knn_ord_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [Brute Force Algorithm] | Ordinal Encoding (With Standardization)', knn_cv_ord_std,\n",
    "                        y_train, knn_ord_std_pred_train, knn_ord_std_pred_train_proba, \n",
    "                        y_val, knn_ord_std_pred_val, knn_ord_std_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [Brute Force Algorithm] | Ordinal Encoding (With Normalization)', knn_cv_ord_norm,\n",
    "                        y_train, knn_ord_norm_pred_train, knn_ord_norm_pred_train_proba, \n",
    "                        y_val, knn_ord_norm_pred_val, knn_ord_norm_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [Brute Force Algorithm] | Ordinal Encoding (With Log Transformation)', knn_cv_ord_log,\n",
    "                        y_train, knn_ord_log_pred_train, knn_ord_log_pred_train_proba, \n",
    "                        y_val, knn_ord_log_pred_val, knn_ord_log_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [Brute Force Algorithm] | One-Hot Encoding', knn_cv_ohe,\n",
    "                        y_train, knn_ohe_pred_train, knn_ohe_pred_train_proba, \n",
    "                        y_val, knn_ohe_pred_val, knn_ohe_pred_val_proba, classification_report=False)\n",
    "\n",
    "# Dataframe with the results of the models\n",
    "df_results_train = pd.DataFrame(models_results_train).T\n",
    "df_results_val = pd.DataFrame(models_results_val).T\n",
    "\n",
    "# Display the results\n",
    "display_side_by_side(df_results_train, df_results_val, \n",
    "                     titles=['Training Set', 'Validation Set'],\n",
    "                     super_title='Results of the K-Nearest Neighbors [Brute Force Algorithm] Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2512c58d",
   "metadata": {},
   "source": [
    "#### **KNN - KD Tree** <sup>[**[3.1]**](https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.NearestNeighbors.html)</sup> <a class='anchor' id='knn-kd-tree'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- K-Nearest Neighbors [KD Tree Algorithm] -------------------------------------------------\n",
    "# ################################ Ordinal Encoding\n",
    "# ============ Original Data\n",
    "knn_ord_kd = KNeighborsClassifier(algorithm='kd_tree')\n",
    "knn_cv_ord_kd = cross_validate(knn_ord_kd,X_train_ordinal_encoded,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_kd.fit(X_train_ordinal_encoded, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_kd_pred_train = knn_ord_kd.predict(X_train_ordinal_encoded)\n",
    "knn_ord_kd_pred_train_proba = knn_ord_kd.predict_proba(X_train_ordinal_encoded)\n",
    "\n",
    "knn_ord_kd_pred_val = knn_ord_kd.predict(X_val_ordinal_encoded)\n",
    "knn_ord_kd_pred_val_proba = knn_ord_kd.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ============ With Standardization\n",
    "knn_ord_std_kd = KNeighborsClassifier(algorithm='kd_tree')\n",
    "knn_cv_ord_std_kd = cross_validate(knn_ord_std_kd,X_train_standardized,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_std_kd.fit(X_train_standardized, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_std_kd_pred_train = knn_ord_std_kd.predict(X_train_standardized)\n",
    "knn_ord_std_kd_pred_train_proba = knn_ord_std_kd.predict_proba(X_train_standardized)\n",
    "\n",
    "knn_ord_std_kd_pred_val = knn_ord_std_kd.predict(X_validation_standardized)\n",
    "knn_ord_std_kd_pred_val_proba = knn_ord_std_kd.predict_proba(X_validation_standardized)\n",
    "\n",
    "# ============ With Normalization\n",
    "knn_ord_norm_kd = KNeighborsClassifier(algorithm='kd_tree')\n",
    "knn_cv_ord_norm_kd = cross_validate(knn_ord_norm_kd,X_train_norm,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_norm_kd.fit(X_train_norm, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_norm_kd_pred_train = knn_ord_norm_kd.predict(X_train_norm)\n",
    "knn_ord_norm_kd_pred_train_proba = knn_ord_norm_kd.predict_proba(X_train_norm)\n",
    "\n",
    "knn_ord_norm_kd_pred_val = knn_ord_norm_kd.predict(X_val_ordinal_encoded)\n",
    "knn_ord_norm_kd_pred_val_proba = knn_ord_norm_kd.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ============ With Log Transformation\n",
    "knn_ord_log_kd = KNeighborsClassifier(algorithm='kd_tree')\n",
    "knn_cv_ord_log_kd = cross_validate(knn_ord_log_kd,X_train_log,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_log_kd.fit(X_train_log, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_log_kd_pred_train = knn_ord_log_kd.predict(X_train_log)\n",
    "knn_ord_log_kd_pred_train_proba = knn_ord_log_kd.predict_proba(X_train_log)\n",
    "\n",
    "knn_ord_log_kd_pred_val = knn_ord_log_kd.predict(X_val_ordinal_encoded)\n",
    "knn_ord_log_kd_pred_val_proba = knn_ord_log_kd.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ################################ One-Hot Encoding\n",
    "knn_ohe_kd = KNeighborsClassifier(algorithm='kd_tree')\n",
    "knn_cv_ohe_kd = cross_validate(knn_ohe_kd,X_train_ohe,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ohe_kd.fit(X_train_ohe, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ohe_kd_pred_train = knn_ohe_kd.predict(X_train_ohe)\n",
    "knn_ohe_kd_pred_train_proba = knn_ohe_kd.predict_proba(X_train_ohe)\n",
    "\n",
    "knn_ohe_kd_pred_val = knn_ohe_kd.predict(X_val_ohe)\n",
    "knn_ohe_kd_pred_val_proba = knn_ohe_kd.predict_proba(X_val_ohe)\n",
    "\n",
    "# Time of Execution KNN (KD Tree Algorithm) >> 395m 11s ~7h (Infeasible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9df71",
   "metadata": {},
   "source": [
    "> The KD Tree algorithm is used to reduce the time complexity of the brute-force algorithm.\n",
    "\n",
    "> However, the KD Tree algorithm is [**not suitable for high-dimensional data**](https://stackoverflow.com/questions/58059912/why-does-kd-tree-take-more-time-than-brute)/ [**many variables**](https://stackoverflow.com/questions/5751114/nearest-neighbors-in-high-dimensional-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Metrics & Confusion Matrix\n",
    "classification_metrics('K-Nearest Neighbors [KD Tree Algorithm] | Ordinal Encoding (Original Data)', knn_cv_ord_kd,\n",
    "                       y_train, knn_ord_kd_pred_train, knn_ord_kd_pred_train_proba, \n",
    "                       y_val, knn_ord_kd_pred_val, knn_ord_kd_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [KD Tree Algorithm] | Ordinal Encoding (With Standardization)', knn_cv_ord_std_kd,\n",
    "                        y_train, knn_ord_std_kd_pred_train, knn_ord_std_kd_pred_train_proba, \n",
    "                        y_val, knn_ord_std_kd_pred_val, knn_ord_std_kd_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [KD Tree Algorithm] | Ordinal Encoding (With Normalization)', knn_cv_ord_norm_kd,\n",
    "                        y_train, knn_ord_norm_kd_pred_train, knn_ord_norm_kd_pred_train_proba, \n",
    "                        y_val, knn_ord_norm_kd_pred_val, knn_ord_norm_kd_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [KD Tree Algorithm] | Ordinal Encoding (With Log Transformation)', knn_cv_ord_log_kd,\n",
    "                        y_train, knn_ord_log_kd_pred_train, knn_ord_log_kd_pred_train_proba, \n",
    "                        y_val, knn_ord_log_kd_pred_val, knn_ord_log_kd_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [KD Tree Algorithm] | One-Hot Encoding', knn_cv_ohe_kd,\n",
    "                        y_train, knn_ohe_kd_pred_train, knn_ohe_kd_pred_train_proba, \n",
    "                        y_val, knn_ohe_kd_pred_val, knn_ohe_kd_pred_val_proba, classification_report=False)\n",
    "\n",
    "# Dataframe with the results of the models\n",
    "df_results_train = pd.DataFrame(models_results_train).T\n",
    "df_results_val = pd.DataFrame(models_results_val).T\n",
    "\n",
    "# Display the results\n",
    "display_side_by_side(df_results_train, df_results_val, \n",
    "                     titles=['Training Set', 'Validation Set'],\n",
    "                     super_title='Results of the K-Nearest Neighbors [KD Tree Algorithm] Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c614c",
   "metadata": {},
   "source": [
    "#### **KNN - Ball Tree** <sup>[**[3.2]**](https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.NearestNeighbors.html)</sup> <a class='anchor' id='knn-ball-tree'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ec532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- K-Nearest Neighbors [Ball Tree Algorithm] -------------------------------------------------\n",
    "# ################################ Ordinal Encoding\n",
    "# ============ Original Data\n",
    "knn_ord_bt = KNeighborsClassifier(algorithm='ball_tree')\n",
    "knn_cv_ord_bt = cross_validate(knn_ord_bt,X_train_ordinal_encoded,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_bt.fit(X_train_ordinal_encoded, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_bt_pred_train = knn_ord_bt.predict(X_train_ordinal_encoded)\n",
    "knn_ord_bt_pred_train_proba = knn_ord_bt.predict_proba(X_train_ordinal_encoded)\n",
    "\n",
    "knn_ord_bt_pred_val = knn_ord_bt.predict(X_val_ordinal_encoded)\n",
    "knn_ord_bt_pred_val_proba = knn_ord_bt.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ============ With Standardization\n",
    "knn_ord_std_bt = KNeighborsClassifier(algorithm='ball_tree')\n",
    "knn_cv_ord_std_bt = cross_validate(knn_ord_std_bt,X_train_standardized,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_std_bt.fit(X_train_standardized, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_std_bt_pred_train = knn_ord_std_bt.predict(X_train_standardized)\n",
    "knn_ord_std_bt_pred_train_proba = knn_ord_std_bt.predict_proba(X_train_standardized)\n",
    "\n",
    "knn_ord_std_bt_pred_val = knn_ord_std_bt.predict(X_validation_standardized)\n",
    "knn_ord_std_bt_pred_val_proba = knn_ord_std_bt.predict_proba(X_validation_standardized)\n",
    "\n",
    "# ============ With Normalization\n",
    "knn_ord_norm_bt = KNeighborsClassifier(algorithm='ball_tree')\n",
    "knn_cv_ord_norm_bt = cross_validate(knn_ord_norm_bt,X_train_norm,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_norm_bt.fit(X_train_norm, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_norm_bt_pred_train = knn_ord_norm_bt.predict(X_train_norm)\n",
    "knn_ord_norm_bt_pred_train_proba = knn_ord_norm_bt.predict_proba(X_train_norm)\n",
    "\n",
    "knn_ord_norm_bt_pred_val = knn_ord_norm_bt.predict(X_val_ordinal_encoded)\n",
    "knn_ord_norm_bt_pred_val_proba = knn_ord_norm_bt.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ============ With Log Transformation\n",
    "knn_ord_log_bt = KNeighborsClassifier(algorithm='ball_tree')\n",
    "knn_cv_ord_log_bt = cross_validate(knn_ord_log_bt,X_train_log,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ord_log_bt.fit(X_train_log, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ord_log_bt_pred_train = knn_ord_log_bt.predict(X_train_log)\n",
    "knn_ord_log_bt_pred_train_proba = knn_ord_log_bt.predict_proba(X_train_log)\n",
    "\n",
    "knn_ord_log_bt_pred_val = knn_ord_log_bt.predict(X_val_ordinal_encoded)\n",
    "knn_ord_log_bt_pred_val_proba = knn_ord_log_bt.predict_proba(X_val_ordinal_encoded)\n",
    "\n",
    "# ################################ One-Hot Encoding\n",
    "knn_ohe_bt = KNeighborsClassifier(algorithm='ball_tree')\n",
    "knn_cv_ohe_bt = cross_validate(knn_ohe_bt,X_train_ohe,y_train,cv=5)\n",
    "\n",
    "# Train the model\n",
    "knn_ohe_bt.fit(X_train_ohe, y_train)\n",
    "\n",
    "# Predictions\n",
    "knn_ohe_bt_pred_train = knn_ohe_bt.predict(X_train_ohe)\n",
    "knn_ohe_bt_pred_train_proba = knn_ohe_bt.predict_proba(X_train_ohe)\n",
    "\n",
    "knn_ohe_bt_pred_val = knn_ohe_bt.predict(X_val_ohe)\n",
    "knn_ohe_bt_pred_val_proba = knn_ohe_bt.predict_proba(X_val_ohe)\n",
    "\n",
    "## Time of Execution KNN (Ball Tree Algorithm) = 148 28s >> 40m ('brute' algorithm) -> Not compensatory if we use all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8debe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Metrics & Confusion Matrix\n",
    "classification_metrics('K-Nearest Neighbors [Ball Tree Algorithm] | Ordinal Encoding (Original Data)', knn_cv_ord_bt,\n",
    "                       y_train, knn_ord_bt_pred_train, knn_ord_bt_pred_train_proba, \n",
    "                       y_val, knn_ord_bt_pred_val, knn_ord_bt_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [Ball Tree Algorithm] | Ordinal Encoding (With Standardization)', knn_cv_ord_std_bt,\n",
    "                        y_train, knn_ord_std_bt_pred_train, knn_ord_std_bt_pred_train_proba, \n",
    "                        y_val, knn_ord_std_bt_pred_val, knn_ord_std_bt_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [Ball Tree Algorithm] | Ordinal Encoding (With Normalization)', knn_cv_ord_norm_bt,\n",
    "                        y_train, knn_ord_norm_bt_pred_train, knn_ord_norm_bt_pred_train_proba, \n",
    "                        y_val, knn_ord_norm_bt_pred_val, knn_ord_norm_bt_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [Ball Tree Algorithm] | Ordinal Encoding (With Log Transformation)', knn_cv_ord_log_bt,\n",
    "                        y_train, knn_ord_log_bt_pred_train, knn_ord_log_bt_pred_train_proba, \n",
    "                        y_val, knn_ord_log_bt_pred_val, knn_ord_log_bt_pred_val_proba, classification_report=False)\n",
    "\n",
    "classification_metrics('K-Nearest Neighbors [Ball Tree Algorithm] | One-Hot Encoding', knn_cv_ohe_bt,\n",
    "                        y_train, knn_ohe_bt_pred_train, knn_ohe_bt_pred_train_proba, \n",
    "                        y_val, knn_ohe_bt_pred_val, knn_ohe_bt_pred_val_proba, classification_report=False)\n",
    "\n",
    "# Dataframe with the results of the models\n",
    "df_results_train = pd.DataFrame(models_results_train).T\n",
    "df_results_val = pd.DataFrame(models_results_val).T\n",
    "\n",
    "# Display the results\n",
    "display_side_by_side(df_results_train, df_results_val, \n",
    "                     titles=['Training Set', 'Validation Set'],\n",
    "                     super_title='Results of the K-Nearest Neighbors [Ball Tree Algorithm] Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb0d60d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f02325",
   "metadata": {},
   "source": [
    "> **Note:** Since we have not covered more algorithms in class yet, the notebook for the **Homework** was tested with the algorithms above. For the next phase, we intend to continue testing this classification problem with the remaining algorithms, such as the following, with the aim of improving the performance of the model on the benchmark **F1-Score (Macro)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e37ddd5",
   "metadata": {},
   "source": [
    "### **Neural Network [<sup>[4]</sup>](https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html)** <a class='anchor' id='neural-network'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7461714e3b1b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T20:24:04.987262Z",
     "start_time": "2024-10-13T20:24:04.984885Z"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6bbd860a401e3",
   "metadata": {},
   "source": [
    "### **Decision Tree[<sup>[5]</sup>](https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html)** <a class='anchor' id='decision-tree'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e5938",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c9cc20b4cf6da",
   "metadata": {},
   "source": [
    "### **Random Forest[<sup>[6]</sup>](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html)** <a class='anchor' id='random-forest'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6633ce1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e9b0127415789",
   "metadata": {},
   "source": [
    "### **Support Vector Machine (SVM)[<sup>[7]</sup>](https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html)** <a class='anchor' id='svm'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cc7292",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de31aca10ac6f1cc",
   "metadata": {},
   "source": [
    "### **Gradient Boosting[<sup>[8]</sup>](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)** <a class='anchor' id='gradient-boosting'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc860b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204995d589f8431f",
   "metadata": {},
   "source": [
    "### <a class='anchor' id='3_1'></a> **🧪 Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777817f8e7b430d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T14:30:27.518251Z",
     "start_time": "2024-10-12T14:30:27.515445Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# Save the results in a Excel file\n",
    "df_results_train.index.name = 'Model'\n",
    "df_results_val.index.name = 'Model'\n",
    "\n",
    "df_results_train.to_excel('./[ML]_Project_EDAOutputs_Group33/Modeling/Models_Results_08.11.2024.xlsx',          ################# Change the day\n",
    "                          sheet_name='Train_AndreSilvestre')                                                    ################# Change the name of the sheet\n",
    "df_results_val.to_excel('./[ML]_Project_EDAOutputs_Group33/Modeling/Models_Results_08.11.2024.xlsx',            ################# Change the day\n",
    "                        sheet_name='Validation_AndreSilvestre')                                                 ################# Change the name of the sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39861b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85cc48b2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style='font-size:30px;font-weight: bold;'>\n",
    "\n",
    "Hypothetically\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The best model until 11.11.2024 is the K-Nearest Neighbors [Ball Tree Algorithm] with One-Hot Encoding.\n",
    "\n",
    "# # Train the best model\n",
    "# knn_ohe = KNeighborsClassifier(algorithm='auto', \n",
    "#                                weights='distance', \n",
    "#                                n_neighbors=5)\n",
    "# knn_ohe.fit(X_train_ohe, y_train)\n",
    "\n",
    "# # Predictions\n",
    "# knn_ohe_bt_pred_train = knn_ohe_bt.predict(X_train_ohe)\n",
    "# knn_ohe_bt_pred_train_proba = knn_ohe_bt.predict_proba(X_train_ohe)\n",
    "\n",
    "# knn_ohe_bt_pred_val = knn_ohe_bt.predict(X_val_ohe)\n",
    "# knn_ohe_bt_pred_val_proba = knn_ohe_bt.predict_proba(X_val_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c570899f31ef3ff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d330ec1b5a3314e",
   "metadata": {},
   "source": [
    "### <a class='anchor' id='3_2'></a> **📏 Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classification Metrics & Confusion Matrix\n",
    "# classification_metrics('K-Nearest Neighbors [Ball Tree Algorithm] | One-Hot Encoding', knn_cv_ohe_bt,\n",
    "#                         y_train, knn_ohe_bt_pred_train, knn_ohe_bt_pred_train_proba, \n",
    "#                         y_val, knn_ohe_bt_pred_val, knn_ohe_bt_pred_val_proba, classification_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a05f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AUC-ROC Curve\n",
    "# # Source: https://scikit-learn.org/stable/auto_examples/model_selection/plot_det.html#plot-roc-and-det-curves\n",
    "\n",
    "# fig, [ax_roc, ax_det] = plt.subplots(1, 2, figsize=(11, 5))\n",
    "\n",
    "# classifiers = {\n",
    "#     \"Train\": knn_ohe_bt,\n",
    "#     \"Validation\": knn_ohe_bt\n",
    "# }\n",
    "\n",
    "# for name, clf in classifiers.items():\n",
    "#     clf.fit(X_train, y_train)\n",
    "\n",
    "#     RocCurveDisplay.from_estimator(clf, X_train_ohe, y_train_encoded, ax=ax_roc, name=name)\n",
    "#     DetCurveDisplay.from_estimator(clf, X_val_ohe, y_val_encoded, ax=ax_det, name=name)\n",
    "\n",
    "# ax_roc.set_title(\"Receiver Operating Characteristic (ROC) curves\")\n",
    "# ax_det.set_title(\"Detection Error Tradeoff (DET) curves\")\n",
    "\n",
    "# ax_roc.grid(linestyle=\"--\")\n",
    "# ax_det.grid(linestyle=\"--\")\n",
    "\n",
    "# plt.legend()\n",
    "# sns.despine(right=True, top=True)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig('./[ML]_Project_EDAOutputs_Group33/Modeling/AUC_ROC_DET_Curves_08.11.2024.png')          ################# Change the day\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a650501fbd12d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T14:30:42.274079Z",
     "start_time": "2024-10-12T14:30:42.270890Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# [To be continued...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7add73692b9d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T14:30:42.461218Z",
     "start_time": "2024-10-12T14:30:42.457750Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3b51b510a378ca3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68462a4e54cb358e",
   "metadata": {},
   "source": [
    "### <a class='anchor' id='3_3'></a> **📈 Model Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ae13517df275e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:51:01.134240Z",
     "start_time": "2024-10-06T14:51:01.131638Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# # Optimizing the hyperparameters of the best model\n",
    "# # ------------------------------------------- Grid Search Cross Validation -------------------------------------------\n",
    "# # Source: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# # Hyperparameters to be optimized\n",
    "# k_range = list(range(1, 31))              # Number of neighbors to use by default for kneighbors queries.\n",
    "# param_grid = {\n",
    "#     'n_neighbors': k_range,               # Default: 5 -> Number of neighbors to use by default for kneighbors queries.\n",
    "#     'weights': ['uniform', 'distance'],   # Default: 'uniform' -> weight function used in prediction. 'distance' -> closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "#     'p': [1, 2]                           # Default: 2 -> Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.\n",
    "# }\n",
    "\n",
    "# # Grid Search Cross Validation\n",
    "# grid_search = GridSearchCV(knn_ohe,                 # Model\n",
    "#                            param_grid,              # Hyperparameters\n",
    "#                            cv=5,                    # Cross-Validation with 5 folds\n",
    "#                            scoring='f1_macro',      # Metric to optimize\n",
    "#                            n_jobs=-1,               # Use all processors (parallelize the execution -> faster)\n",
    "#                            return_train_score=True, # Return the training score\n",
    "#                            verbose=2)               # Print messages (- > 1 : the computation time for each fold and parameter candidate is displayed;\n",
    "#                                                     #                 - > 2 : the score is also displayed;\n",
    "\n",
    "# # Train the GridSearchCV\n",
    "# grid_search.fit(X_train_ohe, y_train_encoded)\n",
    "\n",
    "# # Best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "# best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# print('Best Hyperparameters:\\n', best_params)\n",
    "# print('Best Score:\\n', best_score)\n",
    "# print('Best Estimator:\\n', best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the optimization results in a Excel file\n",
    "# df_results = pd.DataFrame(grid_search.cv_results_)\n",
    "# df_results.to_excel('./[ML]_Project_EDAOutputs_Group33/Modeling/GridSearch_Results_11.11.2024.xlsx')                ################# Change the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c55461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the results of the Grid Search\n",
    "# # Source: https://www.kaggle.com/code/melihkanbay/knn-best-parameters-gridsearchcv\n",
    "\n",
    "# # Get the results of the Grid Search\n",
    "# grid_mean_scores = grid_search.cv_results_['mean_test_score']\n",
    "# print(grid_mean_scores)\n",
    "\n",
    "# # Plot the results of the Grid Search - Best K\n",
    "# plt.plot(k_range, grid_mean_scores, color='#08519C', marker='o', markersize=5)\n",
    "# plt.xlabel('Value of K for KNN', fontsize=12, fontweight='bold')\n",
    "# plt.ylabel('Cross-Validated Accuracy', fontsize=12, fontweight='bold')\n",
    "# plt.title('Grid Search Cross-Validation Results | Best K', fontsize=14, fontweight='bold')\n",
    "\n",
    "# sns.despine(right=True, top=True)  \n",
    "# plt.savefig('./[ML]_Project_EDAOutputs_Group33/Modeling/Grid_Search_CV_Best_K_11.11.2024.png', dpi=200, bbox_inches='tight')  ################# Change the name of the file\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the best model with the best hyperparameters\n",
    "# best_knn_ohe_bt = KNeighborsClassifier(**best_params)\n",
    "# best_knn_ohe_bt.fit(X_train_ohe, y_train)\n",
    "\n",
    "# # Predictions\n",
    "# best_knn_ohe_bt_pred_train = best_knn_ohe_bt.predict(X_train_ohe)\n",
    "# best_knn_ohe_bt_pred_train_proba = best_knn_ohe_bt.predict_proba(X_train_ohe)\n",
    "\n",
    "# best_knn_ohe_bt_pred_val = best_knn_ohe_bt.predict(X_val_ohe)\n",
    "# best_knn_ohe_bt_pred_val_proba = best_knn_ohe_bt.predict_proba(X_val_ohe)\n",
    "\n",
    "# # Classification Metrics & Confusion Matrix\n",
    "# classification_metrics('K-Nearest Neighbors [Ball Tree Algorithm] | One-Hot Encoding (Optimized)', grid_search,\n",
    "#                         y_train, best_knn_ohe_bt_pred_train, best_knn_ohe_bt_pred_train_proba, \n",
    "#                         y_val, best_knn_ohe_bt_pred_val, best_knn_ohe_bt_pred_val_proba, classification_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81efb2247d823541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:51:01.700166Z",
     "start_time": "2024-10-06T14:51:01.697774Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# # ROC Curve\n",
    "# # Train\n",
    "# fpr_train, tpr_train, thresholds_train = roc_curve(y_train, best_knn_ohe_bt_pred_train_proba[:,1])\n",
    "# roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "# # Validation\n",
    "# fpr_val, tpr_val, thresholds_val = roc_curve(y_val, best_knn_ohe_bt_pred_val_proba[:,1])\n",
    "# roc_auc_val = auc(fpr_val, tpr_val)\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(8,5))\n",
    "# plt.plot(fpr_train, tpr_train, label='ROC Train (area = %0.2f)' % roc_auc_train)\n",
    "# plt.plot(fpr_val, tpr_val, label='ROC Validation (area = %0.2f)' % roc_auc_val)\n",
    "# plt.plot([0, 1], [0, 1],'r--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('\\nFalse Positive Rate', fontsize=10, fontweight='bold')\n",
    "# plt.ylabel('True Positive Rate\\n', fontsize=10, fontweight='bold')\n",
    "# plt.title('Receiver Operating Characteristic (ROC Curve)\\n', fontweight='bold', fontsize=14)\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# sns.despine(right=True, top=True)\n",
    "# plt.savefig('./[ML]_Project_EDAOutputs_Group33/Modeling/ROC_Curve_KNN_OHE_BT_Optimized_11.11.2024.png', dpi=300, bbox_inches='tight') ####### Change the name of the file\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47386269a38625",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ef4c7353c33b4",
   "metadata": {},
   "source": [
    "### 📊 **Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a86fb1977da0b10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:51:33.139565Z",
     "start_time": "2024-10-06T14:51:33.136075Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# [To be continued...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accb01eecd62499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T14:51:33.607961Z",
     "start_time": "2024-10-06T14:51:33.605457Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b82496a685ee8baa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada486ffe254bb0",
   "metadata": {},
   "source": [
    "## 🔮 **Test Data Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea63f2904166c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:33:32.536692Z",
     "start_time": "2024-10-19T23:33:32.518306Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Best Model\n",
    "# best_model = best_knn_ohe_bt\n",
    "\n",
    "# # Fit best model with the whole data -> Train + Validation (Try to improve the model performance on the test data)\n",
    "# best_model.fit(pd.concat([X_train_ohe, X_val_ohe]), pd.concat([y_train_encoded, y_val_encoded]))\n",
    "\n",
    "# # Predictions on the test_data\n",
    "# pred_test_ord = best_model.predict(test_data_ordinal_encoded)\n",
    "# pred_test_ohe = best_model.predict(test_data_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864194b3cc3c278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:33:33.230513Z",
     "start_time": "2024-10-19T23:33:33.091615Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# # Dictionary with the mapping of the predicted values\n",
    "# claim_injury_type_dict_swapped = {1: \"1. CANCELLED\", 2: \"2. NON-COMP\", 3: \"3. MED ONLY\", 4: \"4. TEMPORARY\",\n",
    "#                                   5: \"5. PPD SCH LOSS\", 6: \"6. PPD NSL\", 7: \"7. PTD\", 8: \"8. DEATH\"}\n",
    "\n",
    "# # Create a DataFrame with the 'ID' and the 'Predicted' columns\n",
    "# submission_data = pd.DataFrame({'Claim Identifier': test_data['Claim Identifier'], 'Claim Injury Type': pred_test_ohe})\n",
    "# submission_data['Claim Injury Type'] = submission_data['Claim Injury Type'].map(claim_injury_type_dict_swapped)\n",
    "# submission_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486952ea7b2abfa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44821ed2896d8592",
   "metadata": {},
   "source": [
    "## 📋 **CSV Export - Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a88f8d5d4f3f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T23:33:35.891333Z",
     "start_time": "2024-10-19T23:33:35.702692Z"
    },
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# # Each submission in Kaggle should have different names and should have the version name in the following format \n",
    "# # – GroupXX_VersionXX.csv (for example, Group 1 submitted his 8th version, the file should be named Group01__Version08.csv)\n",
    "\n",
    "# submission_data.to_csv('submissions/Group33_Version01.csv', index=False, header=True, sep=',')    # 11.11.2024\n",
    "# # submission_data.to_csv('submissions/Group33_Version02.csv', index=False, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff3bdf66c1f233",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
